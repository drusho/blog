{
  
    
        "post0": {
            "title": "Data Analysis of /r/Politics Subreddit",
            "content": ". Notebook Created by David Rusho . Github | Linkedin | Twitter | . Introduction . About Reddit . Sources: . Wikipedia | Understanding Reddit: A beginner’s guide to the front page of the internet | . What is Reddit? As of February 2021, Reddit ranks as the 18th-most-visited website in the world and 7th most-visited website in the U.S., according to Alexa Internet. Reddit is an American social news aggregation, web content rating, and discussion website. Registered members submit content to the site such as links, text posts, images, and videos, which are then voted up or down by other members. What is a subreddit Posts are organized by subject into user-created boards called &quot;communities&quot; or &quot;subreddits&quot;, which cover a variety of topics such as news, politics, religion, science, movies, video games, music, books, sports, fitness, cooking, pets, and image-sharing. Upvoting and Downvoting Submissions with more up-votes appear towards the top of their subreddit and, if they receive enough up-votes, ultimately on the site&#39;s front page Subreddit Tabs At the top of each page on Reddit, you will see a selection of tabs marked Hot, New, Rising, Controversial, Top, Gilded, and Wiki. Here’s what they mean. Hot posts are the posts that have been getting the most upvotes and comments recently on that subreddit. Goals . Details This notebook will focus on &#39;Hot&#39; (see &#39;What are subreddit tabs&#39;) posts due to their focus on upvotes and recent comments. Data from /r/politics will be scrapped using python library Praw. Analysis will include determining top posts for this subreddit and understanding what factors contributed to their ranking beyond most upvotes and comments. Such as the correlation between comments and points, word frequency and semantic analysis of post titles Results . Correlation of Post Score and Number of Comments Heatmap run through Seaborn showed there was a very positive correlation between the number of comments and the score of a posts (0.89). Word Frequency of Post Titles Word frequency showed that presidents Biden and Trump were the most popular key words, followed by &#39;GOP&#39;. Sentiment Analysis The Majority of posts in /r/politics were found be Neutral, followed by negative. Setup Data Exploration . Import Libraries . !pip install praw !pip install vaderSentiment !pip install texthero . . from configparser import ConfigParser import datetime as dt import matplotlib.pyplot as plt import numpy as np import pandas as pd import plotly.express as px import plotly.graph_objects as go import praw import seaborn as sns import texthero as herofrom from texthero import preprocessing from texthero import stopwords from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer import warnings warnings.filterwarnings(&#39;ignore&#39;) . . Praw (Reddit API) Setup . # praw setup reddit = praw.Reddit(client_id = cid, #peronal use script client_secret = csec, #secret token usernme = username, #profile username password = password, #profile password user_agent = ua, #user agent check_for_async=False) . . Organize and Clean Data . Scrap 500 Reddit Posts from /r/poltics from &#39;Hot&#39; tab. . # list for df conversion posts = [] # select a subreddit to scrape sub = &#39;politics&#39; # return 500 new posts new_bets = reddit.subreddit(sub).hot(limit=500) # return selected reddit post attributes for post in new_bets: posts.append([post.title, post.selftext, post.score, post.upvote_ratio, post.num_comments, post.created_utc, post.is_original_content, post.url]) # create df, rename columns, and make dtype for all data a str posts = pd.DataFrame(posts, columns=[&#39;title&#39;, &#39;post&#39;, &#39;score&#39;, &#39;upvote_ratio&#39;, &#39;comments&#39;, &#39;created&#39;, &#39;original_content&#39;, &#39;url&#39;], dtype=&#39;str&#39;) posts.sample(3) . . title post score upvote_ratio comments created original_content url . 428 A judge blocked Florida Gov. Ron DeSantis&#39; &#39;de... | | 1563 | 0.98 | 107 | 1625166787.0 | False | https://www.businessinsider.com/florida-ron-de... | . 483 Garland orders halt to any further federal exe... | | 147 | 0.92 | 1 | 1625182268.0 | False | https://abcnews.go.com/Politics/garland-orders... | . 218 Biden administration formally launches effort ... | | 3784 | 0.98 | 245 | 1625270143.0 | False | https://www.inquirer.com/news/nation-world/bid... | . Column Descriptions . Heading Description . title | The title of the submission. | . post | The submissions’ selftext - an empty string if a link post. | . score | The number of upvotes for the submission. | . upvote_ratio | The percentage of upvotes from all votes on the submission. | . comments | The number of comments on the submission. | . created | Time the submission was created, represented in Unix Time. | . original_content | Whether or not the submission has been set as original content. | . url | The URL the submission links to, or the permalink if a selfpost. | . Change &#39;created&#39; Column Dtype to datetime . # created timestamp column to represent correct created column data posts[&#39;created&#39;] = pd.to_datetime(posts[&#39;created&#39;], unit=&#39;s&#39;) posts[&#39;created&#39;].head(1) . 0 2021-07-05 16:00:02 Name: created, dtype: datetime64[ns] . . Show Dataframe Dtypes . # change dytpe of score and comments cols to int posts[[&#39;comments&#39;,&#39;score&#39;]] = posts[[&#39;comments&#39;,&#39;score&#39;]].astype(&#39;int&#39;) posts[&#39;upvote_ratio&#39;] = posts[&#39;upvote_ratio&#39;].astype(&#39;float&#39;) . . posts.info() . . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 500 entries, 0 to 499 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 title 500 non-null object 1 post 500 non-null object 2 score 500 non-null int64 3 upvote_ratio 500 non-null float64 4 comments 500 non-null int64 5 created 500 non-null datetime64[ns] 6 original_content 500 non-null object 7 url 500 non-null object dtypes: datetime64[ns](1), float64(1), int64(2), object(4) memory usage: 31.4+ KB . Clean Post Titles (NLP Preprossing) . #Clean post titles using texthero posts[&#39;clean_title&#39;] = herofrom.clean(posts[&#39;title&#39;]) posts[&#39;clean_title&#39;].sample(3) . . 497 nancy pelosi signals hard line formation janua... 430 foreign media skewer joe biden &#39;barely cogent ... 281 biden administration freezes u assets myanmar ... Name: clean_title, dtype: object . Begin Data Exploration . Set Global Plot Colors and Print Date . Color Reference . # set global plot colors #plotly marker colors mcolors = &#39;#1f77b4&#39; #light blue #wordcloud letters cmaps = &#39;Blues&#39; #light blue #plotly backround wtbckgnd = {&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255, 0.9)&quot;} #white background from datetime import date today = date.today() . . Top 10 Popular Posts by Score . # Top 10 Popular posts based on score top_posts = posts.groupby([&#39;title&#39;])[&#39;score&#39;,&#39;upvote_ratio&#39;].sum().sort_values(by=&#39;score&#39;,ascending=False).reset_index() top_posts[[&#39;score&#39;,&#39;upvote_ratio&#39;,&#39;title&#39;]].head(3) . . score upvote_ratio title . 0 59394 | 0.82 | Charles Booker makes it official, announces ru... | . 1 56462 | 0.89 | Dominion has subpoenaed Rudy Giuliani, Sidney ... | . 2 51924 | 1.83 | Biden says teachers deserve ‘a raise, not just... | . Word Frequency of Post Titles (Wordcloud) . # Word cloud of top words from clean_title herofrom.wordcloud(posts.clean_title, max_words=200, contour_color=&#39;&#39;, background_color=&#39;white&#39;, colormap=cmaps, height = 500, width=800) . . Top 25 Words From Post Titles (Bar Plot) . # create new dateframe of top words tw = herofrom.visualization.top_words(posts[&#39;clean_title&#39;]).head(20).to_frame() tw.reset_index(inplace=True) tw.rename(columns={&#39;index&#39;:&#39;word&#39;,&#39;clean_title&#39;:&#39;freq&#39;},inplace=True) #remove word less than 2 chars tw2 = tw[tw[&#39;word&#39;].str.len() &gt;=2] tw2 = tw2.sort_values(by=&#39;freq&#39;,ascending=False) tw2.head(3) . . word freq . 0 biden | 85 | . 1 trump | 67 | . 2 gop | 43 | . Word Frequency of Post Titles (Bar Plot) . # Top 25 Words From Post Titles fig = go.Figure([go.Bar(x=tw2.word, y=tw2.freq, textposition=&#39;auto&#39;)]) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&#39;Top 25 Words in /r/politics Post Titles ({today})&#39;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, yaxis=dict(title=&#39;Word Count&#39;)) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Post Scores vs Comments (Scatter Plot) . # Post Scores vs Comments fig = go.Figure(data=go.Scatter(x=posts.comments, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&quot;/r/politics Posts&#39; Scores vs Comments ({today})&quot;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Post Score&quot;, yaxis_title=&quot;No. of Comments&quot;,) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Post Scores by Post Counts (Histrogram Plot) . fig = px.histogram(posts, x=&quot;score&quot;) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&#39;Post Scores by Post Counts&#39;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, yaxis=dict(title=&#39;Post Count&#39;), xaxis=dict(title=&#39;Post Score&#39;)) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Sentiment Analysis of Post Titles . Scale for determining sentiment . positive: compound score&gt;=0.05 neutral: compound score between -0.05 and 0.05 negative: compound score&lt;=-0.05 . #Sentiment Analysis of Post Titles analyzer = SentimentIntensityAnalyzer() posts[&#39;neg&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neg&#39;]) posts[&#39;neu&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neu&#39;]) posts[&#39;pos&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;pos&#39;]) posts[&#39;compound&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;compound&#39;]) posts[[&#39;title&#39;,&#39;neg&#39;,&#39;neu&#39;,&#39;pos&#39;,&#39;compound&#39;]].sample(3) . . title neg neu pos compound . 392 Biden struggles to answer Russia question at p... | 0.200 | 0.800 | 0.000 | -0.3612 | . 354 Child tax credit checks will start arriving th... | 0.000 | 0.794 | 0.206 | 0.3818 | . 271 Trump under fire for provocative email to supp... | 0.147 | 0.675 | 0.178 | 0.1280 | . Create Sentiment Column Using Compound Numbers . # sentiment col def sentiment(compscore): if compscore &gt;= 0.05: return &#39;positive&#39; elif -0.05 &lt; compscore &lt; 0.05: return &#39;neutral&#39; elif compscore &lt;=-0.05: return &#39;negative&#39; posts[&#39;sentiment&#39;] = posts.compound.apply(sentiment) posts[[&#39;title&#39;,&#39;neg&#39;,&#39;neu&#39;,&#39;pos&#39;,&#39;compound&#39;,&#39;sentiment&#39;]].sample(3) . . title neg neu pos compound sentiment . 126 Op-Ed: What does it mean to be American? Ask a... | 0.000 | 1.000 | 0.000 | 0.0000 | neutral | . 11 Want Better Policing? Make It Easier To Fire B... | 0.330 | 0.279 | 0.391 | 0.0258 | neutral | . 176 They kept the wheels on democracy as Trump tri... | 0.158 | 0.842 | 0.000 | -0.4939 | negative | . Sentiment of Post Titles (Histogram Plot) . # posts.sentiment.value_counts().to_frame().reset_index() fig = px.histogram(posts, x=&quot;compound&quot;, color=&quot;sentiment&quot;, # color_discrete_sequence= px.colors.sequential.Blues color_discrete_sequence=[&quot;#1f77b4&quot;, &quot;#97C3E1&quot;, &quot;#559ACA&quot;]) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&quot;Sentiment of /r/politics Posts ({today})&quot;, &#39;y&#39;:0.95,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Compound Score&quot;, yaxis_title=&quot;No. of Posts&quot;,) # fig.update_traces(marker_color=mcolors) #set market colors to light blue . . . . Post Scores vs Compound Sentiment Score (Scatter Plot) . # Post Scores vs Compound Sentiment Score fig = go.Figure(data=go.Scatter(x=posts.compound, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: &quot;/r/politics Posts&#39; Scores vs Comments&quot;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Compound Sentiment Score&quot;, yaxis_title=&quot;Scores&quot;,) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Correlation of Dataframe (Heatmap) . Note: Plotly and Heatmaps Plotly currently doesn&#39;t have simple solution for using dataframes directly with heatmaps. # Heatmap of Dataframe mask = np.triu(np.ones_like(posts.corr(), dtype=np.bool))# adjust mask and df mask = mask[1:, :-1] corr = posts.corr().iloc[1:,:-1].copy()# plot heatmap fig, ax = plt.subplots(figsize=(11, 9)) sb.heatmap(corr, mask=mask, annot=True, fmt=&quot;.2f&quot;, cmap=&#39;Blues&#39;, vmin=-1, vmax=1, cbar_kws={&quot;shrink&quot;: .8})# yticks plt.yticks(rotation=0) plt.show() . . Conclusion . Correlation of Post Score and Number of Comments Heatmap run through Seaborn showed there was a very positive correlation between the number of comments and the score of a posts (0.89). Word Frequency of Post Titles Word frequency showed that presidents Biden and Trump were the most popular key words, followed by &#39;GOP&#39;. Sentiment Analysis The Majority of posts in /r/politics were found be Neutral, followed by negative. Resources . PRAW: The Python Reddit API Wrapper . | Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python — Twitter, Reddit, Genius and More Collect Text through APIs and Web Scraping . | How to scrape Reddit with Python . | Try TextHero: The Absolute Simplest way to Clean and Analyze Text in Pandas . | How to Use Texthero to Prepare a Text-based Dataset for Your NLP Project . | How to Run Sentiment Analysis in Python using VADER . | How to read and write configuration (.ini) file in python . | Understanding Reddit: A beginner’s guide to the front page of the internet . | Tools Used . Details Pandas, Plotly, Praw (reddit api tool), Texthero (NLP tool)",
            "url": "https://drusho.github.io/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/07/05/_07_05_Reddit_Politics_Analysis.html",
            "relUrl": "/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/07/05/_07_05_Reddit_Politics_Analysis.html",
            "date": " • Jul 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Cleaning and Merging US Firework Injuries Data",
            "content": ". Notebook Created by David Rusho . Github | Linkedin | Twitter | . Introduction . Goals . Combine and clean firework injury data . About the Data . Source: Firework Injury Reports . Details The following notebook represents steps that were taken to organize and clean 5 excel files that consist of incident reports involving fireforks over the past 5 years from the CPSC (United States Consumer Product Safety Commision). The data needed to be converted to csv since reading excel into pandas is extremely slow. CSV did create larger files but the trade off for increased reading speeds was worth it. This was done manually through Excel and then exporting each file as a csv. If there were more files a more &quot;pythonic&quot; method would have been used to save time. Begin Cleaning Process . Import Libraries . import pandas as pd . . Merge csv Files . filelist = [&#39;NEISS_2016.csv&#39;,&#39;NEISS_2017.csv&#39;,&#39;NEISS_2018.csv&#39;,&#39;NEISS_2019.csv&#39;,&#39;NEISS_2020.csv&#39;] df = pd.concat(map(pd.read_csv, filelist)) df.head(3) . CPSC_Case_Number Treatment_Date Age Sex Race Other_Race Hispanic Body_Part Diagnosis Other_Diagnosis ... Fire_Involvement Alcohol Drug Product_1 Product_2 Product_3 Narrative Stratum PSU Weight . 0 160101845 | 1/1/16 | 92 | 1 | 0 | NaN | NaN | 79 | 57 | NaN | ... | 0 | NaN | NaN | 1645 | 1807 | 0 | 92YOM TRYINGO TO TAKE OFF PANTS AND LOST BALAN... | M | 63 | 103.2251 | . 1 160101847 | 1/1/16 | 90 | 1 | 0 | NaN | NaN | 79 | 57 | NaN | ... | 0 | NaN | NaN | 670 | 0 | 0 | 90YOM FELL GETTING OUT OF A RECLINER CHAIR AND... | M | 63 | 103.2251 | . 2 160101848 | 1/1/16 | 71 | 2 | 0 | NaN | NaN | 79 | 57 | NaN | ... | 0 | NaN | NaN | 1807 | 0 | 0 | 71YOF SLIPPED AND FELL TO HER WET KITCHEN FLOO... | M | 63 | 103.2251 | . 3 rows × 25 columns . . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1791854 entries, 0 to 309369 Data columns (total 25 columns): # Column Dtype -- 0 CPSC_Case_Number int64 1 Treatment_Date object 2 Age int64 3 Sex int64 4 Race int64 5 Other_Race object 6 Hispanic float64 7 Body_Part int64 8 Diagnosis int64 9 Other_Diagnosis object 10 Body_Part_2 float64 11 Diagnosis_2 float64 12 Other_Diagnosis_2 object 13 Disposition int64 14 Location int64 15 Fire_Involvement int64 16 Alcohol float64 17 Drug float64 18 Product_1 int64 19 Product_2 int64 20 Product_3 int64 21 Narrative object 22 Stratum object 23 PSU int64 24 Weight float64 dtypes: float64(6), int64(13), object(6) memory usage: 355.4+ MB . . Reduce DataFrame Size . Filter results to only diplay firework related incidents . Fireworks product code is &#39;1313&#39; | . df1 = df.query(&#39;(Product_1 == 1313) | (Product_2 == 1313) | (Product_3 == 1313)&#39;) df1.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1532 entries, 57 to 308881 Data columns (total 25 columns): # Column Non-Null Count Dtype -- -- 0 CPSC_Case_Number 1532 non-null int64 1 Treatment_Date 1532 non-null object 2 Age 1532 non-null int64 3 Sex 1532 non-null int64 4 Race 1532 non-null int64 5 Other_Race 88 non-null object 6 Hispanic 701 non-null float64 7 Body_Part 1532 non-null int64 8 Diagnosis 1532 non-null int64 9 Other_Diagnosis 146 non-null object 10 Body_Part_2 267 non-null float64 11 Diagnosis_2 267 non-null float64 12 Other_Diagnosis_2 28 non-null object 13 Disposition 1532 non-null int64 14 Location 1532 non-null int64 15 Fire_Involvement 1532 non-null int64 16 Alcohol 701 non-null float64 17 Drug 701 non-null float64 18 Product_1 1532 non-null int64 19 Product_2 1532 non-null int64 20 Product_3 1532 non-null int64 21 Narrative 1532 non-null object 22 Stratum 1532 non-null object 23 PSU 1532 non-null int64 24 Weight 1532 non-null float64 dtypes: float64(6), int64(13), object(6) memory usage: 311.2+ KB . . Reduce Columns . Remove unnecessary columns . # reduce df size and clean na values df2 = df1[[&#39;Treatment_Date&#39;,&#39;Age&#39;,&#39;Sex&#39;,&#39;Body_Part&#39;,&#39;Diagnosis&#39;,&#39;Disposition&#39;,&#39;Location&#39;,&#39;Alcohol&#39;,&#39;Drug&#39;,&#39;Narrative&#39;]].fillna(&#39;&#39;).reset_index(drop=True) df2.head() . Treatment_Date Age Sex Body_Part Diagnosis Disposition Location Alcohol Drug Narrative . 0 1/1/16 | 39 | 1 | 77 | 53 | 1 | 1 | | | 39YOM WAS LIGHTING BOTTLE ROCKETS AND ONE FLEW... | . 1 1/1/16 | 10 | 1 | 82 | 51 | 1 | 1 | | | 10YOM SUSTAINED A THERMAL BURN TO HAND AFTER H... | . 2 1/1/16 | 35 | 1 | 31 | 62 | 4 | 0 | | | 35YOM HIT IN THE CHEST WITH A MORTAR TYPE FIRE... | . 3 1/1/16 | 13 | 1 | 77 | 53 | 1 | 0 | | | 13YOM SOMEONE POINTED FIREWORKS AT HIM FROM 10... | . 4 1/1/16 | 216 | 1 | 31 | 51 | 1 | 0 | | | 16MOM FAMILY PLAYING WITH FIREWORKS AND ONE SH... | . . Fix Sex Data . # Fix Sex columns df2.Sex = df2.Sex.replace(1,&quot;Male&quot;).replace(2,&quot;Female&quot;) df2.head(2) . Treatment_Date Age Sex Body_Part Diagnosis Disposition Location Alcohol Drug Narrative . 0 1/1/16 | 39 | Male | 77 | 53 | 1 | 1 | | | 39YOM WAS LIGHTING BOTTLE ROCKETS AND ONE FLEW... | . 1 1/1/16 | 10 | Male | 82 | 51 | 1 | 1 | | | 10YOM SUSTAINED A THERMAL BURN TO HAND AFTER H... | . . Import Incident Local Dataframe . Dataframe was manual input taken from the 2020 NEISS Coding Manual.pdf . local_df = pd.read_pickle(&#39;df_incident_local.pkl&#39;) local_df . . Code Incident Locale . 0 1 | Home | . 1 2 | Farm/Ranch | . 2 4 | Street or highway | . 3 5 | Other public property | . 4 6 | Manufactured (mobile) home | . 5 7 | Industrial place | . 6 8 | School | . 7 9 | Place of recreation or sports | . 8 0 | Not recorded | . Fix and Mege Incident Locale . # fix Incident Locale df3 = pd.merge(df2, local_df, left_on=&#39;Disposition&#39;, right_on=&#39;Code&#39;).drop([&#39;Code&#39;,&#39;Location&#39;],axis=1) df3.sample(3) . Treatment_Date Age Sex Body_Part Diagnosis Disposition Alcohol Drug Narrative Incident Locale . 1221 5/29/16 | 4 | Female | 31 | 51 | 4 | | | 4YOF W/BURNS TO CHEST &amp; FINGER TIPS 2/2 PLAYIN... | Street or highway | . 541 7/4/18 | 15 | Male | 36 | 72 | 1 | | | 15YOM WAS HIT IN BACK OF LEGS WHEN LARGE FIREW... | Home | . 457 8/2/17 | 25 | Male | 76 | 51 | 1 | | | 25YOM PUT FIREWORKS BOX BON FIRE FIREWORKS WEN... | Home | . . Import Body Part Dataframe . Dataframe was manual input taken from the 2020 NEISS Coding Manual.pdf . body_part_df = pd.read_pickle(&#39;df_body_part.pkl&#39;) body_part_df . . Code Body_Part . 0 0 | Internal | . 1 30 | Shoulder | . 2 31 | Upper Trunk | . 3 32 | Elbow | . 4 33 | Lower Arm | . 5 34 | Wrist | . 6 35 | Knee | . 7 36 | Lower Leg | . 8 37 | Ankle | . 9 38 | Pubic Region | . 10 75 | Head | . 11 76 | Face | . 12 77 | Eyeball | . 13 79 | Lower Trunk | . 14 80 | Upper Arm | . 15 81 | Upper Leg | . 16 82 | Hand | . 17 83 | Foot | . 18 84 | 25-50&#39;%&#39; of Body | . 19 85 | All Parts of Body | . 20 87 | Not Stated | . 21 88 | Mouth | . 22 89 | Neck | . 23 92 | Finger | . 24 93 | Toe | . 25 94 | Ear | . Fix and Merge Body Part Data . # fix Body Part df4 = pd.merge(df3, body_part_df, left_on=&#39;Body_Part&#39;, right_on=&#39;Code&#39;).drop([&#39;Code&#39;,&#39;Body_Part_x&#39;],axis=1) df4.rename(columns={&#39;Body_Part_y&#39;:&#39;Body_Part&#39;},inplace=True) df4.sample(3) . Treatment_Date Age Sex Diagnosis Disposition Alcohol Drug Narrative Incident Locale Body_Part . 169 7/4/20 | 14 | Male | 56 | 1 | 0.0 | 0.0 | 14YOM WAS PLAYING WITH AND WATCHING FIREWORKS ... | Home | Eyeball | . 63 7/5/17 | 32 | Female | 56 | 1 | | | 32YOF W/FOREIGN BODY IN EYE &amp; CONJ IRRITATION ... | Home | Eyeball | . 1153 7/1/20 | 54 | Male | 50 | 2 | 1.0 | 0.0 | 54 YOM PRESENTED TO THE ER WITH A FIREWORK INJ... | Farm/Ranch | Finger | . . Import Diagnosis Dataframe . Dataframe was manual input taken from the 2020 NEISS Coding Manual.pdf . # import Diagnosis pkl diagnosis_df = pd.read_pickle(&#39;df_diagnosis.pkl&#39;) diagnosis_df . . Diagnosis1 Code . 0 Ingested foreign object | 41 | . 1 Aspirated foreign object | 42 | . 2 Burns, electrical 46 Burns, not specified | 47 | . 3 Burns, scald (from hot liquids or steam) | 48 | . 4 Burns, chemical (caustics, etc.) | 49 | . 5 Amputation | 50 | . 6 Burns, thermal (from flames or hot surface) | 51 | . 7 Concussions | 52 | . 8 Contusions, Abrasions | 53 | . 9 Crushing | 54 | . 10 Dislocation | 55 | . 11 Foreign body | 56 | . 12 Fracture | 57 | . 13 Hematoma | 58 | . 14 Laceration | 59 | . 15 Dental injury | 60 | . 16 Nerve damage | 61 | . 17 Internal organ injury | 62 | . 18 Puncture | 63 | . 19 Strain or Sprain | 64 | . 20 Anoxia | 65 | . 21 Hemorrhage | 66 | . 22 Electric shock | 67 | . 23 Poisoning | 68 | . 24 Submersion (including Drowning) | 69 | . 25 Other/Not Stated | 71 | . 26 Avulsion | 72 | . 27 Burns, radiation (includes all cell damage by ... | 73 | . 28 Dermatitis, Conjunctivitis | 74 | . Fix and Merge Diagnosis Data . # fix Diagnosis df5 = pd.merge(df4, diagnosis_df, left_on=&#39;Diagnosis&#39;, right_on=&#39;Code&#39;).drop([&#39;Code&#39;,&#39;Diagnosis&#39;],axis=1) df5.rename(columns={&#39;Diagnosis1&#39;:&#39;Diagnosis&#39;},inplace=True) df5.sample(3) . Treatment_Date Age Sex Disposition Alcohol Drug Narrative Incident Locale Body_Part Diagnosis . 153 6/10/19 | 58 | Female | 1 | 0.0 | 0.0 | 58YOF FALL AND C/O R KNEE, SHOULDER WHEN NEIGH... | Home | Knee | Contusions, Abrasions | . 250 7/2/20 | 32 | Male | 2 | 0.0 | 0.0 | 32 YOM PESENTS WITH EYE INJURY. PT WAS LIGHTIN... | Farm/Ranch | Eyeball | Other/Not Stated | . 783 7/1/16 | 24 | Female | 1 | | | 24 YO FEMALE HURT FINGER ON A TYPE L SPARKLER.... | Home | Finger | Burns, thermal (from flames or hot surface) | . . Import Disposition Dataframe . Dataframe was manual input taken from the 2020 NEISS Coding Manual.pdf . # import Disposition pkl disposition_df = pd.read_pickle(&#39;df_disposition.pkl&#39;) disposition_df . . Code Disposition . 0 1 | Treated/Untreated and Released | . 1 2 | Treated and transferred to another hospital | . 2 3 | Treated and admitted for hospitalization | . 3 4 | Held for observation | . 4 5 | Left without being seen | . 5 6 | Left against medical advice | . 6 7 | Left without treatment | . 7 8 | Eloped Fatality/DOA/died in the ED/Died after ... | . 8 9 | Not recorded | . Fix and Merge Disposition Data . # fix Disposition df6 = pd.merge(df5, disposition_df, left_on=&#39;Disposition&#39;, right_on=&#39;Code&#39;).drop([&#39;Code&#39;,&#39;Disposition_x&#39;],axis=1) df6.rename(columns={&#39;Disposition_y&#39;:&#39;Disposition&#39;},inplace=True) df6.sample(3) . . Treatment_Date Age Sex Alcohol Drug Narrative Incident Locale Body_Part Diagnosis Disposition . 551 7/4/18 | 11 | Female | | | 11YOF WENT TO LIGHT UNKNOWN FIREWORK (TYPE R),... | Home | Upper Leg | Burns, thermal (from flames or hot surface) | Treated/Untreated and Released | . 374 7/8/17 | 212 | Female | | | 12MOF C/O BURN TO R HAND X1 HOUR PTA S/P GRABB... | Home | Hand | Burns, thermal (from flames or hot surface) | Treated/Untreated and Released | . 159 7/18/16 | 12 | Male | | | 12YOM FOREIGN BODY RT EYE WAS PLAYING W/ &quot;BLAS... | Home | Eyeball | Foreign body | Treated/Untreated and Released | . Export Cleaned Data to csv . df6.to_csv(&#39;injury_clean.csv&#39;) .",
            "url": "https://drusho.github.io/pandas/data%20cleaning/2021/07/05/_06_25_cleaning_fireworks_injury_data.html",
            "relUrl": "/pandas/data%20cleaning/2021/07/05/_06_25_cleaning_fireworks_injury_data.html",
            "date": " • Jul 5, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I have a passion for using data to tell stories and discover meaningful insights. I have been a hobbiest programmer most of life and discovered Data Science and Analytics on accident while looking for methods to automate work projects such as creating advanced spreadsheet formulas for cleaning and merging. At one point I even installed a SuperSQL in Google Sheets as a means to create a locaized database because discovering python and other modern data handling methods. . I’m currently based out of Orlando, FL where I am currenlty enrolled in an MS Data Analytics (Big Data) program at the University of Central Florida. When I’m not programming or reading about Data Science you can usually find my playing with photography, practicing yoga, or learning to cook some korean/indian food. .",
          "url": "https://drusho.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Dashboards",
          "content": "Tableau . COVID-19 (12/2019 - 06/2020) .",
          "url": "https://drusho.github.io/dashboards/",
          "relUrl": "/dashboards/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Home",
          "content": "",
          "url": "https://drusho.github.io/",
          "relUrl": "/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://drusho.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
{
  
    
        "post0": {
            "title": "Analysis of US Firework Sales and Injuries",
            "content": ". Introduction . Goals . Provide an overview of incidents that involve fireworks. . Age Group(s) most affected | Frequency of Injury Type(s) | . Provide sales figures for fireworks across the US. . State sales totals all states | . Conclusions . Injury Data . Age Group(s) most affected 0-20 age group showed the highest rate of injury. | Injury rates by age decreased with age | 60+ age groups showed the lowest rate of injury | . | Frequency of Injury Type(s) Hand, Face, and Eye injuries were the most common. | Injuries to lower extemities were less common | . | . Sales Data . The state of Missouri held the record for most spent on fireworks (over $250 million over the past 5 years). . | For comparision, Alaska spent around $560,000 with the last five years . | . Resources . Source (Injury Data): Firework Injury Reports . Consisted multiple excel incident reports involving fireworks over the past 5 years taken from the U.S. Consumer Product Safety Commission (CPSC). . NEISS injury data are gathered from the emergency departments (ED) of 96 hospitals selected as a probability sample of all U.S. hospitals with 24-hour EDs and at least 6 inpatient beds. Each participating NEISS hospital is hand-selected by CPSC because it provides an important representation of all other hospitals of its size and unique characteristics in the U.S. . | Source (Sales Data): USA Trade Census . Sales and Trade data each state regarding fireworks. Reports data range from 2016 to April 2021. . | Tools Used . Matplotlib | Pandas | Seaborn | Plotly | . Import Libraries . # install libraries to save plotly images to disk %%capture !pip install kaleido !pip install plotly&gt;=4.0.0 !wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca !chmod +x /usr/local/bin/orca !apt-get install xvfb libgtk2.0-0 libgconf-2-4 . import matplotlib.pyplot as plt import numpy as np import pandas as pd import plotly.express as px import seaborn as sns import warnings warnings.filterwarnings(&#39;ignore&#39;) . Import Firework Injury Datasets . # Import clean injury dataframe injury = &#39;https://github.com/drusho/fireworks_data_exploration/raw/main/data/data_clean/df_injury_clean.csv&#39; df_injury = pd.read_csv(injury,usecols=[1,2,3,4,5,6,7,8,9,10]) df_injury.head(3) . Treatment_Date Age Sex Alcohol Drug Narrative Incident Locale Body_Part Diagnosis Disposition . 0 1/1/16 | 39 | Male | NaN | NaN | 39YOM WAS LIGHTING BOTTLE ROCKETS AND ONE FLEW... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . 1 1/1/16 | 13 | Male | NaN | NaN | 13YOM SOMEONE POINTED FIREWORKS AT HIM FROM 10... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . 2 7/5/16 | 31 | Female | NaN | NaN | A 31YOF WAS STRUCK TO EYE WITH PIECE OF FIRECR... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1532 entries, 0 to 1531 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 Treatment_Date 1532 non-null datetime64[ns] 1 Age 1532 non-null int64 2 Sex 1532 non-null object 3 Alcohol 701 non-null float64 4 Drug 701 non-null float64 5 Narrative 1532 non-null object 6 Incident Locale 1532 non-null object 7 Body_Part 1532 non-null object 8 Diagnosis 1532 non-null object 9 Disposition 1532 non-null object dtypes: datetime64[ns](1), float64(2), int64(1), object(6) memory usage: 119.8+ KB . Converting Alcohol and Drug columns to &#39;yes/no&#39; values . Fill nan values to 0.0 | Convert all values to float type | Convert 0.0 to No and 1.0 to Yes | . Counting Drug and Alchol Use . The number of people injuried with positive results for drug or alcohol use was very insignificant compared to overall count of injuries. . Visualizing Incident Counts by Year (Bar Plot) . Fixing Age Column . The Age column list not only numeric ages but also includes category codes for individuals under the age of 2 year old. Individuals that are under 2 years old are given a code starting with 200 combined with their age in months. . Age Code . Age Code Description . 0 | No Recorded Age | . 2 | 2 Years Old | . 45 | 45 Years Old | . 100 | 100 Years Old | . 102 | 102 Years Old | . 201 | Three Weeks Old | . 201 | Four Weeks Old | . 201 | Seven Weeks Old | . 202 | Ten Weeks Old | . 209 | Nine Months Old | . 212 | Twelve months (one year) | . 218 | Eighteen months | . If the patient is older than 115 years old, code the age as 115 and indicate the actual age in the Comment. If the ED record indicates the patient was born on January 1, 1900, please verify the patient’s age with hospital staff – some hospitals use this date when the patient’s age is unknown. . Please note: CPSC prefers that coders use the Date of Birth variable in lieu of the age variable. Mistakes in coded ages are common when patients have birthdays after the date of treatment and before the NEISS coder codes the case. Hospital medical record systems automatically update the age of the patient daily. . Visualizing Age Groups (Histogram) . The histogram below shows that the majority of firework related injuries that were reported occured with indivuals under the age of 40. The largest grouping belonged to individuals under the age of 20, which is also below the legal drinking age in the US. . Visualizing Incident Counts by Age (Bar Plot) . Visualizing Age, Year, Gender (Swarm Plot) . Visualizing Incident Counts by Disposition (Bar Plot) . Visualizing Incident Counts by Diagnosis (Bar Plot) . Import Firework Sales Data (State) . sales_state = &#39;https://github.com/drusho/fireworks_data_exploration/raw/main/data/data_raw/State%20Imports%20by%20HS%20Commodities.csv&#39; df_sales_st = pd.read_csv(sales_state,skiprows=4,usecols=[0,1,2,3]) df_sales_st.head() . State Commodity Time Total Value ($US) . 0 Alabama | 360410 Fireworks | 2016 | 29,602,090 | . 1 Alabama | 360410 Fireworks | 2017 | 19,396,430 | . 2 Alabama | 360410 Fireworks | 2018 | 26,399,895 | . 3 Alabama | 360410 Fireworks | 2019 | 28,353,392 | . 4 Alabama | 360410 Fireworks | 2020 | 23,141,950 | . . Web Scrap of State Abbreviations . #WebScrap State Abbreviations #scrap state names and abbrev states_abrev = pd.read_html(&#39;https://abbreviations.yourdictionary.com/articles/state-abbrev.html&#39;)[0].iloc[1:,:2] #scrap US territory names and abbrev territories = pd.read_html(&#39;https://abbreviations.yourdictionary.com/articles/state-abbrev.html&#39;)[1].iloc[[2,5],:2] #merge dfs st_at = states_abrev.merge(territories,how=&#39;outer&#39;).sort_values(by=0).reset_index(drop=True) #rename cols st_at.rename(columns={0:&#39;State&#39;,1:&#39;Abbrevation&#39;},inplace=True) st_at.head() . State Abbrevation . 0 Alabama | AL | . 1 Alaska | AK | . 2 Arizona | AZ | . 3 Arkansas | AR | . 4 California | CA | . . #merge abbrevation with state sales data df_sales_st2 = df_sales_st.merge(st_at,how=&#39;inner&#39;) df_sales_st2.head() . State Commodity Time Total Value ($US) Abbrevation . 0 Alabama | 360410 Fireworks | 2016 | 29,602,090 | AL | . 1 Alabama | 360410 Fireworks | 2017 | 19,396,430 | AL | . 2 Alabama | 360410 Fireworks | 2018 | 26,399,895 | AL | . 3 Alabama | 360410 Fireworks | 2019 | 28,353,392 | AL | . 4 Alabama | 360410 Fireworks | 2020 | 23,141,950 | AL | . . Visualizating State Sales (Bar Plot) . . . Visualizating State Sales (Scatter Plot) . . . Visualizating State Sales (Heatmap Plot of US) . . . Putting It All Together . Combining injury and sales data. . Sales and Injury Correlation | . Prediect which Injuries are likely to Occur in 2021-2022 . # Total Sales groupby Year sales_year = df_sales_st2.groupby(df_sales_st2[&#39;Time&#39;].dt.year).sum().reset_index(drop=False) sales_year.rename(columns={&#39;Time&#39;:&#39;Year&#39;,&#39;Total Value ($US)&#39;:&#39;Sales&#39;},inplace=True) sales_year . . Year Sales . 0 2016 | 307825710 | . 1 2017 | 279962808 | . 2 2018 | 331072715 | . 3 2019 | 320021354 | . 4 2020 | 300987616 | . 5 2021 | 157186415 | . # df_injury.groupby([&#39;Treatment_Date&#39;] df_injury_count = df_injury.groupby(df_injury[&#39;Treatment_Date&#39;].dt.year)[&#39;Age&#39;].count().reset_index(name=&#39;Count&#39;) df_injury_count.rename(columns={&#39;Treatment_Date&#39;:&#39;Year&#39;},inplace=True) df_injury_count . . Year Count . 0 2016 | 268 | . 1 2017 | 329 | . 2 2018 | 234 | . 3 2019 | 261 | . 4 2020 | 440 | . # Merge sales and injury dfs on year df_merged = sales_year.merge(df_injury_count,how=&#39;left&#39;) df_merged . . Year Sales Count . 0 2016 | 307825710 | 268.0 | . 1 2017 | 279962808 | 329.0 | . 2 2018 | 331072715 | 234.0 | . 3 2019 | 320021354 | 261.0 | . 4 2020 | 300987616 | 440.0 | . 5 2021 | 157186415 | NaN | . # Correlation df_merged.corr() . . Year Sales Count . Year 1.000000 | -0.585906 | 0.529818 | . Sales -0.585906 | 1.000000 | -0.590087 | . Count 0.529818 | -0.590087 | 1.000000 | . Summary . Injuries . Ages 0-20 showed the highest rate of injury. Injury rates by age decrease with age. The 60+ age groups showed the lowest rate of injury . Injuries to the hands, face, and eyes were the most common, while injuries to lower extemities were less common. . Sales . The state of Missouri held the record for most spent on fireworks (over 250 million dollars over the past 5 years). For comparision, Alaska spent around 560,000 dollars with the last five years . Correlation . There was no significate correlation between the number of injuries in a year compared to the number of sales. .",
            "url": "https://drusho.github.io/pandas/plotly/seaborn/2021/07/02/_07_03_Analysis_of_US_Firework_Sales_and_Injuries.html",
            "relUrl": "/pandas/plotly/seaborn/2021/07/02/_07_03_Analysis_of_US_Firework_Sales_and_Injuries.html",
            "date": " • Jul 2, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Data Analysis of /r/Politics Subreddit",
            "content": "Goals of Project . Find the top posts by score | Determine if score correlates with comments | Determine word frequency of post titles | Semantics analysis of post titles | . . Tools Used: . Pandas: organized data and create dataframes | Plotly: create interactive charts/visualizations | Praw: scrape reddit subs | Texthero: provide semantic analysis of post titles | . pip install praw . . pip install vaderSentiment . . pip install texthero . . Import Libraries . from configparser import ConfigParser import datetime as dt import matplotlib.pyplot as plt import pandas as pd import plotly.graph_objects as go import praw import texthero as herofrom from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer . . reddit = praw.Reddit(client_id=login[&#39;cid&#39;], client_secret=login[&#39;csec&#39;], user_agent=login[&#39;ua&#39;], check_for_async=False) . . Sample of reddit posts from /r/poltics out of 500 posts . posts = [] # select a subreddit to scrape sub = &#39;politics&#39; # return 500 new posts new_bets = reddit.subreddit(sub).hot(limit=500) # return selected reddit post attributes for post in new_bets: posts.append([post.title, post.selftext, post.score, post.upvote_ratio, post.num_comments, post.created_utc, post.is_original_content, post.url]) # create df, rename columns, and make dtype for all data a str posts = pd.DataFrame(posts, columns=[&#39;title&#39;, &#39;post&#39;, &#39;score&#39;, &#39;upvote_ratio&#39;, &#39;comments&#39;, &#39;created&#39;, &#39;original_content&#39;, &#39;url&#39;], dtype=&#39;str&#39;) posts.sample(3) . title post score upvote_ratio comments created original_content url . 306 People fleeing New York and New Jersey for the... | | 110 | 0.93 | 28 | 1618653755.0 | False | https://www.inquirer.com/politics/pennsylvania... | . 273 60 years after the Bay of Pigs invasion, many ... | | 138 | 0.86 | 46 | 1618669266.0 | False | https://www.cnn.com/2021/04/17/politics/bay-of... | . 276 Alleged sex trafficking victim may be cooperat... | | 923 | 0.98 | 55 | 1618629552.0 | False | https://thehill.com/homenews/house/548800-alle... | . # return 500 new posts new_bets = reddit.subreddit(sub).hot(limit=500) # return selected reddit post attributes for post in new_bets: posts.append([post.title, post.selftext, post.score, post.upvote_ratio, post.num_comments, post.created_utc, post.is_original_content, post.url]) # create df, rename columns, and make dtype for all data a str posts = pd.DataFrame(posts, columns=[&#39;title&#39;, &#39;post&#39;, &#39;score&#39;, &#39;upvote_ratio&#39;, &#39;comments&#39;, &#39;created&#39;, &#39;original_content&#39;, &#39;url&#39;], dtype=&#39;str&#39;) posts.sample(3) . . Column Descriptions . Heading Description . title | The title of the submission. | . post | The submissions’ selftext - an empty string if a link post. | . score | The number of upvotes for the submission. | . upvote_ratio | The percentage of upvotes from all votes on the submission. | . comments | The number of comments on the submission. | . created | Time the submission was created, represented in Unix Time. | . original_content | Whether or not the submission has been set as original content. | . url | The URL the submission links to, or the permalink if a selfpost. | . posts[&#39;created&#39;] = pd.to_datetime(posts[&#39;created&#39;], unit=&#39;s&#39;) posts[&#39;created&#39;].head(3) . 0 2021-04-13 15:09:23 1 2021-04-18 20:37:47 2 2021-04-18 21:40:39 Name: created, dtype: datetime64[ns] . # change dytpe of score and comments cols to int posts[[&#39;comments&#39;,&#39;score&#39;]] = posts[[&#39;comments&#39;,&#39;score&#39;]].astype(&#39;int&#39;) posts[&#39;upvote_ratio&#39;] = posts[&#39;upvote_ratio&#39;].astype(&#39;float&#39;) . . posts.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 500 entries, 0 to 499 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 title 500 non-null object 1 post 500 non-null object 2 score 500 non-null int64 3 upvote_ratio 500 non-null float64 4 comments 500 non-null int64 5 created 500 non-null datetime64[ns] 6 original_content 500 non-null object 7 url 500 non-null object dtypes: datetime64[ns](1), float64(1), int64(2), object(4) memory usage: 31.4+ KB . posts[&#39;clean_title&#39;] = herofrom.clean(posts[&#39;title&#39;]) posts[&#39;clean_title&#39;].sample(10) . 477 gop donors hobnobbing person dems sticking zoom 221 observer view joe biden&#39; sanctions russia 227 treatment ban creates uncertainty trans youth ... 264 &#39;comically evil&#39; marjorie taylor greene lauren... 123 criticism biden says raise u cap refugee admis... 388 feds rescind health care funding agreement wou... 82 indianapolis shooting red flag never flew 405 chicago mayor slams trash rumors indicates res... 172 ted cruz among small number republicans opposi... 2 bush calls congress tone harsh rhetoric immigr... Name: clean_title, dtype: object . # shorten post titles posts[&#39;short_clean_title&#39;] = posts.clean_title.str[:100]+ &#39;...&#39; . . Top 10 Popular posts based on score . top_posts = posts.groupby([&#39;title&#39;])[&#39;score&#39;,&#39;upvote_ratio&#39;].sum().sort_values(by=&#39;score&#39;,ascending=False).reset_index() top_posts[[&#39;score&#39;,&#39;upvote_ratio&#39;,&#39;title&#39;]].head(10) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead. . score upvote_ratio title . 0 63001 | 0.87 | Mitch McConnell blocked the Ruth Bader Ginsbur... | . 1 57647 | 0.77 | There was Trump-Russia collusion — and Trump p... | . 2 55677 | 0.91 | Americans overwhelmingly say marijuana should ... | . 3 53364 | 0.89 | &#39;Completely Unreasonable&#39;: Dems Slam GOP Deman... | . 4 48970 | 0.90 | GOP Rep. Adam Kinzinger calls on party to expe... | . 5 47043 | 0.79 | John Kerry apologises for Donald Trump’s ‘rene... | . 6 45462 | 0.91 | ‘It’s long overdue’: Rep. Young breaks with GO... | . 7 39308 | 0.85 | GOP Rep. Lauren Boebert Blasted For Absurd Twe... | . 8 35346 | 0.91 | Republicans Who Voted to Impeach Trump Are Out... | . 9 34983 | 0.84 | AOC accuses Chicago prosecutor of ‘lying’ abou... | . Word cloud of top words from clean_title . herofrom.wordcloud(posts.clean_title,width = 500, height= 400,background_color=&#39;White&#39;) . tw = herofrom.visualization.top_words(posts[&#39;clean_title&#39;]).head(20).to_frame() tw.reset_index(inplace=True) tw.rename(columns={&#39;index&#39;:&#39;word&#39;,&#39;clean_title&#39;:&#39;freq&#39;},inplace=True) . . Top 25 Words From Post Titles . fig = go.Figure([go.Bar(x=tw.word, y=tw.freq,textposition=&#39;auto&#39;)]) fig.update_layout( title={ &#39;text&#39;: &quot;Top 25 Words Found in /r/politics Post Titles&quot;, &#39;y&#39;:0.88, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}) fig.show() . . . Post Scores vs Comments . # Post Scores vs Comments fig = go.Figure(data=go.Scatter(x=posts.comments, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout( title={ &#39;text&#39;: &quot;/r/politics Posts&#39; Scores vs Comments&quot;, &#39;y&#39;:0.88, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Scores&quot;, yaxis_title=&quot;Comments&quot;,) fig.show() . . . . Sentiment Analysis of Post Titles . Scale for determining sentiment . positive: compound score&gt;=0.05 neutral: compound score between -0.05 and 0.05 negative: compound score&lt;=-0.05 . # for i in range(len(sentences)): # vs = analyzer.polarity_scores(sentences[i]) analyzer = SentimentIntensityAnalyzer() posts[&#39;neg&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neg&#39;]) posts[&#39;neu&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neu&#39;]) posts[&#39;pos&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;pos&#39;]) posts[&#39;compound&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;compound&#39;]) posts.sample(3) . title post score upvote_ratio comments created original_content url clean_title short_clean_title neg neu pos compound . 416 Biden Administration Says Russian Intelligence... | | 4289 | 0.97 | 113 | 2021-04-16 01:01:19 | False | https://www.nytimes.com/2021/04/15/us/politics... | biden administration says russian intelligence... | biden administration says russian intelligence... | 0.0 | 0.721 | 0.279 | 0.4767 | . 438 Discussion Thread: Press Secretary Jen Psaki H... | White House Press Secretary Jen Psaki briefs r... | 232 | 0.95 | 134 | 2021-04-16 14:53:33 | False | https://www.reddit.com/r/politics/comments/ms4... | discussion thread press secretary jen psaki ho... | discussion thread press secretary jen psaki ho... | 0.0 | 1.000 | 0.000 | 0.0000 | . 134 Garland rescinds Trump-era restrictions on fed... | | 11243 | 0.99 | 188 | 2021-04-17 14:58:27 | False | https://www.latimes.com/politics/story/2021-04... | garland rescinds trump era restrictions federa... | garland rescinds trump era restrictions federa... | 0.0 | 1.000 | 0.000 | 0.0000 | . fig = go.Figure(data=go.Scatter(x=posts.compound, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout( title={ &#39;text&#39;: &quot;/r/politics Posts&#39; Scores vs Comments&quot;, &#39;y&#39;:0.88, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Compound Sentiment Score&quot;, yaxis_title=&quot;Scores&quot;,) fig.show() . . . Project Resources . PRAW: The Python Reddit API Wrapper . | Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python — Twitter, Reddit, Genius and More Collect Text through APIs and Web Scraping . | How to scrape Reddit with Python . | Try TextHero: The Absolute Simplest way to Clean and Analyze Text in Pandas . | How to Use Texthero to Prepare a Text-based Dataset for Your NLP Project . | How to Run Sentiment Analysis in Python using VADER . | How to read and write configuration (.ini) file in python . |",
            "url": "https://drusho.github.io/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/06/20/Reddit-Politics-Analysis.html",
            "relUrl": "/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/06/20/Reddit-Politics-Analysis.html",
            "date": " • Jun 20, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I have a passion for using data to tell stories and discover meaningful insights. I have been a hobbiest programmer most of life and discovered Data Science and Analytics on accident while looking for methods to automate work projects such as creating advanced spreadsheet formulas for cleaning and merging. At one point I even installed a SuperSQL in Google Sheets as a means to create a locaized database because discovering python and other modern data handling methods. . I’m currently based out of Orlando, FL where I am currenlty enrolled in an MS Data Analytics (Big Data) program at the University of Central Florida. When I’m not programming or reading about Data Science you can usually find my playing with photography, practicing yoga, or learning to cook some korean/indian food. .",
          "url": "https://drusho.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Dashboards",
          "content": "Tableau . COVID-19 (12/2019 - 06/2020) .",
          "url": "https://drusho.github.io/dashboards/",
          "relUrl": "/dashboards/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Home",
          "content": "",
          "url": "https://drusho.github.io/",
          "relUrl": "/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://drusho.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
{
  
    
        "post0": {
            "title": "Data Analysis of /r/Politics Subreddit",
            "content": ". Notebook Created by David Rusho . Github | Linkedin | Twitter | . Introduction . About Reddit . Sources: . Wikipedia | Understanding Reddit: A beginner’s guide to the front page of the internet | . What is Reddit? As of February 2021, Reddit ranks as the 18th-most-visited website in the world and 7th most-visited website in the U.S., according to Alexa Internet. Reddit is an American social news aggregation, web content rating, and discussion website. Registered members submit content to the site such as links, text posts, images, and videos, which are then voted up or down by other members. What is a subreddit Posts are organized by subject into user-created boards called &quot;communities&quot; or &quot;subreddits&quot;, which cover a variety of topics such as news, politics, religion, science, movies, video games, music, books, sports, fitness, cooking, pets, and image-sharing. Upvoting and Downvoting Submissions with more up-votes appear towards the top of their subreddit and, if they receive enough up-votes, ultimately on the site&#39;s front page Subreddit Tabs At the top of each page on Reddit, you will see a selection of tabs marked Hot, New, Rising, Controversial, Top, Gilded, and Wiki. Here’s what they mean. Hot posts are the posts that have been getting the most upvotes and comments recently on that subreddit. Goals . Details This notebook will focus on &#39;Hot&#39; (see &#39;What are subreddit tabs&#39;) posts due to their focus on upvotes and recent comments. Data from /r/politics will be scrapped using python library Praw. Analysis will include determining top posts for this subreddit and understanding what factors contributed to their ranking beyond most upvotes and comments. Such as the correlation between comments and points, word frequency and semantic analysis of post titles Results . Correlation of Post Score and Number of Comments Heatmap run through Seaborn showed there was a very positive correlation between the number of comments and the score of a posts (0.89). Word Frequency of Post Titles Word frequency showed that presidents Biden and Trump were the most popular key words, followed by &#39;GOP&#39;. Sentiment Analysis The Majority of posts in /r/politics were found be Neutral, followed by negative. Setup Data Exploration . Import Libraries . !pip install praw !pip install vaderSentiment !pip install texthero . . from configparser import ConfigParser import datetime as dt import matplotlib.pyplot as plt import numpy as np import pandas as pd import plotly.express as px import plotly.graph_objects as go import praw import seaborn as sns import texthero as herofrom from texthero import preprocessing from texthero import stopwords from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer import warnings warnings.filterwarnings(&#39;ignore&#39;) . . Praw (Reddit API) Setup . # praw setup reddit = praw.Reddit(client_id = cid, #peronal use script client_secret = csec, #secret token usernme = username, #profile username password = password, #profile password user_agent = ua, #user agent check_for_async=False) . . Organize and Clean Data . Scrap 500 Reddit Posts from /r/poltics from &#39;Hot&#39; tab. . # list for df conversion posts = [] # select a subreddit to scrape sub = &#39;politics&#39; # return 500 new posts new_bets = reddit.subreddit(sub).hot(limit=500) # return selected reddit post attributes for post in new_bets: posts.append([post.title, post.selftext, post.score, post.upvote_ratio, post.num_comments, post.created_utc, post.is_original_content, post.url]) # create df, rename columns, and make dtype for all data a str posts = pd.DataFrame(posts, columns=[&#39;title&#39;, &#39;post&#39;, &#39;score&#39;, &#39;upvote_ratio&#39;, &#39;comments&#39;, &#39;created&#39;, &#39;original_content&#39;, &#39;url&#39;], dtype=&#39;str&#39;) posts.sample(3) . . title post score upvote_ratio comments created original_content url . 428 A judge blocked Florida Gov. Ron DeSantis&#39; &#39;de... | | 1563 | 0.98 | 107 | 1625166787.0 | False | https://www.businessinsider.com/florida-ron-de... | . 483 Garland orders halt to any further federal exe... | | 147 | 0.92 | 1 | 1625182268.0 | False | https://abcnews.go.com/Politics/garland-orders... | . 218 Biden administration formally launches effort ... | | 3784 | 0.98 | 245 | 1625270143.0 | False | https://www.inquirer.com/news/nation-world/bid... | . Column Descriptions . Heading Description . title | The title of the submission. | . post | The submissions’ selftext - an empty string if a link post. | . score | The number of upvotes for the submission. | . upvote_ratio | The percentage of upvotes from all votes on the submission. | . comments | The number of comments on the submission. | . created | Time the submission was created, represented in Unix Time. | . original_content | Whether or not the submission has been set as original content. | . url | The URL the submission links to, or the permalink if a selfpost. | . Change &#39;created&#39; Column Dtype to datetime . # created timestamp column to represent correct created column data posts[&#39;created&#39;] = pd.to_datetime(posts[&#39;created&#39;], unit=&#39;s&#39;) posts[&#39;created&#39;].head(1) . 0 2021-07-05 16:00:02 Name: created, dtype: datetime64[ns] . . Show Dataframe Dtypes . # change dytpe of score and comments cols to int posts[[&#39;comments&#39;,&#39;score&#39;]] = posts[[&#39;comments&#39;,&#39;score&#39;]].astype(&#39;int&#39;) posts[&#39;upvote_ratio&#39;] = posts[&#39;upvote_ratio&#39;].astype(&#39;float&#39;) . . posts.info() . . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 500 entries, 0 to 499 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 title 500 non-null object 1 post 500 non-null object 2 score 500 non-null int64 3 upvote_ratio 500 non-null float64 4 comments 500 non-null int64 5 created 500 non-null datetime64[ns] 6 original_content 500 non-null object 7 url 500 non-null object dtypes: datetime64[ns](1), float64(1), int64(2), object(4) memory usage: 31.4+ KB . Clean Post Titles (NLP Preprossing) . #Clean post titles using texthero posts[&#39;clean_title&#39;] = herofrom.clean(posts[&#39;title&#39;]) posts[&#39;clean_title&#39;].sample(3) . . 497 nancy pelosi signals hard line formation janua... 430 foreign media skewer joe biden &#39;barely cogent ... 281 biden administration freezes u assets myanmar ... Name: clean_title, dtype: object . Begin Data Exploration . Set Global Plot Colors and Print Date . Color Reference . # set global plot colors #plotly marker colors mcolors = &#39;#1f77b4&#39; #light blue #wordcloud letters cmaps = &#39;Blues&#39; #light blue #plotly backround wtbckgnd = {&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255, 0.9)&quot;} #white background from datetime import date today = date.today() . . Top 10 Popular Posts by Score . # Top 10 Popular posts based on score top_posts = posts.groupby([&#39;title&#39;])[&#39;score&#39;,&#39;upvote_ratio&#39;].sum().sort_values(by=&#39;score&#39;,ascending=False).reset_index() top_posts[[&#39;score&#39;,&#39;upvote_ratio&#39;,&#39;title&#39;]].head(3) . . score upvote_ratio title . 0 59394 | 0.82 | Charles Booker makes it official, announces ru... | . 1 56462 | 0.89 | Dominion has subpoenaed Rudy Giuliani, Sidney ... | . 2 51924 | 1.83 | Biden says teachers deserve ‘a raise, not just... | . Word Frequency of Post Titles (Wordcloud) . # Word cloud of top words from clean_title herofrom.wordcloud(posts.clean_title, max_words=200, contour_color=&#39;&#39;, background_color=&#39;white&#39;, colormap=cmaps, height = 500, width=800) . . Top 25 Words From Post Titles (Bar Plot) . # create new dateframe of top words tw = herofrom.visualization.top_words(posts[&#39;clean_title&#39;]).head(20).to_frame() tw.reset_index(inplace=True) tw.rename(columns={&#39;index&#39;:&#39;word&#39;,&#39;clean_title&#39;:&#39;freq&#39;},inplace=True) #remove word less than 2 chars tw2 = tw[tw[&#39;word&#39;].str.len() &gt;=2] tw2 = tw2.sort_values(by=&#39;freq&#39;,ascending=False) tw2.head(3) . . word freq . 0 biden | 85 | . 1 trump | 67 | . 2 gop | 43 | . Word Frequency of Post Titles (Bar Plot) . # Top 25 Words From Post Titles fig = go.Figure([go.Bar(x=tw2.word, y=tw2.freq, textposition=&#39;auto&#39;)]) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&#39;Top 25 Words in /r/politics Post Titles ({today})&#39;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, yaxis=dict(title=&#39;Word Count&#39;)) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Post Scores vs Comments (Scatter Plot) . # Post Scores vs Comments fig = go.Figure(data=go.Scatter(x=posts.comments, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&quot;/r/politics Posts&#39; Scores vs Comments ({today})&quot;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Post Score&quot;, yaxis_title=&quot;No. of Comments&quot;,) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Post Scores by Post Counts (Histrogram Plot) . fig = px.histogram(posts, x=&quot;score&quot;) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&#39;Post Scores by Post Counts&#39;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, yaxis=dict(title=&#39;Post Count&#39;), xaxis=dict(title=&#39;Post Score&#39;)) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Sentiment Analysis of Post Titles . Scale for determining sentiment . positive: compound score&gt;=0.05 neutral: compound score between -0.05 and 0.05 negative: compound score&lt;=-0.05 . #Sentiment Analysis of Post Titles analyzer = SentimentIntensityAnalyzer() posts[&#39;neg&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neg&#39;]) posts[&#39;neu&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;neu&#39;]) posts[&#39;pos&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;pos&#39;]) posts[&#39;compound&#39;] = posts[&#39;title&#39;].apply(lambda x:analyzer.polarity_scores(x)[&#39;compound&#39;]) posts[[&#39;title&#39;,&#39;neg&#39;,&#39;neu&#39;,&#39;pos&#39;,&#39;compound&#39;]].sample(3) . . title neg neu pos compound . 392 Biden struggles to answer Russia question at p... | 0.200 | 0.800 | 0.000 | -0.3612 | . 354 Child tax credit checks will start arriving th... | 0.000 | 0.794 | 0.206 | 0.3818 | . 271 Trump under fire for provocative email to supp... | 0.147 | 0.675 | 0.178 | 0.1280 | . Create Sentiment Column Using Compound Numbers . # sentiment col def sentiment(compscore): if compscore &gt;= 0.05: return &#39;positive&#39; elif -0.05 &lt; compscore &lt; 0.05: return &#39;neutral&#39; elif compscore &lt;=-0.05: return &#39;negative&#39; posts[&#39;sentiment&#39;] = posts.compound.apply(sentiment) posts[[&#39;title&#39;,&#39;neg&#39;,&#39;neu&#39;,&#39;pos&#39;,&#39;compound&#39;,&#39;sentiment&#39;]].sample(3) . . title neg neu pos compound sentiment . 126 Op-Ed: What does it mean to be American? Ask a... | 0.000 | 1.000 | 0.000 | 0.0000 | neutral | . 11 Want Better Policing? Make It Easier To Fire B... | 0.330 | 0.279 | 0.391 | 0.0258 | neutral | . 176 They kept the wheels on democracy as Trump tri... | 0.158 | 0.842 | 0.000 | -0.4939 | negative | . Sentiment of Post Titles (Histogram Plot) . # posts.sentiment.value_counts().to_frame().reset_index() fig = px.histogram(posts, x=&quot;compound&quot;, color=&quot;sentiment&quot;, # color_discrete_sequence= px.colors.sequential.Blues color_discrete_sequence=[&quot;#1f77b4&quot;, &quot;#97C3E1&quot;, &quot;#559ACA&quot;]) fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: f&quot;Sentiment of /r/politics Posts ({today})&quot;, &#39;y&#39;:0.95,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Compound Score&quot;, yaxis_title=&quot;No. of Posts&quot;,) # fig.update_traces(marker_color=mcolors) #set market colors to light blue . . . . Post Scores vs Compound Sentiment Score (Scatter Plot) . # Post Scores vs Compound Sentiment Score fig = go.Figure(data=go.Scatter(x=posts.compound, y=posts.score, mode=&#39;markers&#39;, text=posts.title)) # hover text goes here fig.update_layout(wtbckgnd, #set background to white title={&#39;text&#39;: &quot;/r/politics Posts&#39; Scores vs Comments&quot;, &#39;y&#39;:0.88,&#39;x&#39;:0.5,&#39;xanchor&#39;: &#39;center&#39;,&#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Compound Sentiment Score&quot;, yaxis_title=&quot;Scores&quot;,) fig.update_traces(marker_color=mcolors) #set market colors to light blue fig.show() . . . . Correlation of Dataframe (Heatmap) . # Heatmap of Dataframe mask = np.triu(np.ones_like(posts.corr(), dtype=np.bool))# adjust mask and df mask = mask[1:, :-1] corr = posts.corr().iloc[1:,:-1].copy()# plot heatmap fig, ax = plt.subplots(figsize=(11, 9)) sb.heatmap(corr, mask=mask, annot=True, fmt=&quot;.2f&quot;, cmap=&#39;Blues&#39;, vmin=-1, vmax=1, cbar_kws={&quot;shrink&quot;: .8})# yticks plt.yticks(rotation=0) plt.show() . . Conclusion . Correlation of Post Score and Number of Comments Heatmap run through Seaborn showed there was a very positive correlation between the number of comments and the score of a posts (0.89). Word Frequency of Post Titles Word frequency showed that presidents Biden and Trump were the most popular key words, followed by &#39;GOP&#39;. Sentiment Analysis The Majority of posts in /r/politics were found be Neutral, followed by negative. Resources . PRAW: The Python Reddit API Wrapper . | Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python — Twitter, Reddit, Genius and More Collect Text through APIs and Web Scraping . | How to scrape Reddit with Python . | Try TextHero: The Absolute Simplest way to Clean and Analyze Text in Pandas . | How to Use Texthero to Prepare a Text-based Dataset for Your NLP Project . | How to Run Sentiment Analysis in Python using VADER . | How to read and write configuration (.ini) file in python . | Understanding Reddit: A beginner’s guide to the front page of the internet . | Tools Used . Details Pandas, Plotly, Praw (reddit api tool), Texthero (NLP tool)",
            "url": "https://drusho.github.io/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/07/04/_07_05_Reddit_Politics_Analysis.html",
            "relUrl": "/nlp/pandas/plotly/texthero/prawn/reddit/api/2021/07/04/_07_05_Reddit_Politics_Analysis.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "US Firework Sales and Injuries (2016-2021)",
            "content": ". Notebook Created by David Rusho . Github | Linkedin | Twitter | . Introduction . History Facts and concerns . Goals . Details Provide an overview of incidents that involve fireworks. This includes understaing which age groups are most affected and frequency of injury types. Provide sales figures for fireworks across the US. Conclusions . Injuries Ages 0-20 showed the highest rate of injury. Injury rates by age decrease with age. The 60+ age groups showed the lowest rate of injury Injuries to the hands, face, and eyes were the most common, while injuries to lower extemities were less common. Sales The state of Missouri held the record for most spent on fireworks (over 250 million dollars over the past 5 years). For comparision, Alaska spent around 560,000 dollars with the last five years Correlation There was no significate correlation between the number of injuries in a year compared to the number of sales. Import Libraries . # install libraries to save plotly images to disk %%capture !pip install kaleido !pip install plotly&gt;=4.0.0 !wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca !chmod +x /usr/local/bin/orca !apt-get install xvfb libgtk2.0-0 libgconf-2- !pip install texthero . . import matplotlib.pyplot as plt import numpy as np import pandas as pd import plotly.express as px import seaborn as sns import texthero as hero from texthero import preprocessing from texthero import stopwords import warnings warnings.filterwarnings(&#39;ignore&#39;) . . [nltk_data] Downloading package stopwords to /root/nltk_data... [nltk_data] Unzipping corpora/stopwords.zip. . Import Firework Injury Datasets . # Import clean injury dataframe injury = &#39;https://github.com/drusho/fireworks_data_exploration/raw/main/data/data_clean/df_injury_clean.csv&#39; df_injury = pd.read_csv(injury,usecols=[1,2,3,4,5,6,7,8,9,10]) df_injury.head(3) . Treatment_Date Age Sex Alcohol Drug Narrative Incident Locale Body_Part Diagnosis Disposition . 0 1/1/16 | 39 | Male | NaN | NaN | 39YOM WAS LIGHTING BOTTLE ROCKETS AND ONE FLEW... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . 1 1/1/16 | 13 | Male | NaN | NaN | 13YOM SOMEONE POINTED FIREWORKS AT HIM FROM 10... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . 2 7/5/16 | 31 | Female | NaN | NaN | A 31YOF WAS STRUCK TO EYE WITH PIECE OF FIRECR... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . . Displaying Column Data Types . #Change dtype for &#39;Treatment_Date&#39; to datetime dtype df_injury.Treatment_Date = pd.to_datetime(df_injury.Treatment_Date) df_injury.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1532 entries, 0 to 1531 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 Treatment_Date 1532 non-null datetime64[ns] 1 Age 1532 non-null int64 2 Sex 1532 non-null object 3 Alcohol 701 non-null float64 4 Drug 701 non-null float64 5 Narrative 1532 non-null object 6 Incident Locale 1532 non-null object 7 Body_Part 1532 non-null object 8 Diagnosis 1532 non-null object 9 Disposition 1532 non-null object dtypes: datetime64[ns](1), float64(2), int64(1), object(6) memory usage: 119.8+ KB . . Narrative Column Word Frequency (Bar Plot) . The Narrative column contains a detailed description of each injury reported. . #create a custom cleaning pipeline custom_pipeline = [preprocessing.fillna , preprocessing.lowercase , preprocessing.remove_digits , preprocessing.remove_punctuation , preprocessing.remove_diacritics #, preprocessing.remove_stopwords , preprocessing.remove_whitespace] # , preprocessing.stem] #pass the custom_pipeline to the pipeline argument df_injury[&#39;clean_nar&#39;] = hero.clean(df_injury[&#39;Narrative&#39;], pipeline = custom_pipeline) #add a list of stopwords to the stopwords default_stopwords = stopwords.DEFAULT #Call remove_stopwords and pass the custom_stopwords list custom_stopwords = default_stopwords.union(set([&quot;&#39;&quot;,&quot;I&quot;,&quot;r&quot;,&quot;dx&quot;,&quot;i&quot;,&quot;l&quot;,&quot;yom&quot;,&quot;yow&quot;,&quot;pt&quot;,&quot;type&quot;,&quot;p&quot;,&quot;w&quot;])) df_injury[&#39;clean_nar&#39;] = hero.remove_stopwords(df_injury[&#39;clean_nar&#39;], custom_stopwords) tw = hero.visualization.top_words(df_injury[&#39;clean_nar&#39;]).head(20).reset_index() fig = px.bar(tw, x=&#39;index&#39;, y=&#39;clean_nar&#39;, orientation=&#39;v&#39;) fig.update_layout({&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255, 0.9)&quot;}, title={&#39;text&#39;: &quot;Word Frequency for Injury Reports (2016-2021)&quot;, &#39;y&#39;:.98, &#39;x&#39;:.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis=dict(title=&#39;&#39;), yaxis=dict(title=&#39;Word Counts&#39;)) fig.update_traces(marker_color=&#39;#1f77b4&#39;) fig.show() . . . . Wordcloud of Injury Report (2016-2021) . Words are taken from the Narrative column and are narrowed down to the top 200 words. . #Wordcloud from Narrative column using hero hero.wordcloud(df_injury[&#39;clean_nar&#39;], max_words=200,contour_color=&#39;&#39;, background_color=&#39;white&#39;,colormap=&#39;Blues&#39;, height = 500,width=800) . . Converting Alchol/Drug booleans (0,1) values to yes/no . #Converting Alcohol and Drug columns to &#39;yes/no&#39; values #Fill nan values to 0.0 #Convert all values to float type #Convert 0.0 to No and 1.0 to Yes #Change nan values to to 0.0 string df_injury.Alcohol = df_injury[&#39;Alcohol&#39;].fillna(0.0) # Convert dytpe to float df_injury.Alcohol = df_injury.Alcohol.astype(&#39;float&#39;) # Convert Alcohol to Yes/No df_injury.Alcohol = df_injury[&#39;Alcohol&#39;].replace(1.0,&quot;Yes&quot;).replace(0.0,&quot;No&quot;) df_injury.head(2) #Change nan values to to 0.0 string df_injury.Drug = df_injury[&#39;Drug&#39;].fillna(0.0) # Convert dytpe to float df_injury.Drug = df_injury.Drug.astype(&#39;float&#39;) # Convert Drug to Yes/No df_injury.Drug = df_injury[&#39;Drug&#39;].replace(1.0,&quot;Yes&quot;).replace(0.0,&quot;No&quot;) df_injury.head(2) . . Treatment_Date Age Sex Alcohol Drug Narrative Incident Locale Body_Part Diagnosis Disposition . 0 2016-01-01 | 39 | Male | No | No | 39YOM WAS LIGHTING BOTTLE ROCKETS AND ONE FLEW... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . 1 2016-01-01 | 13 | Male | No | No | 13YOM SOMEONE POINTED FIREWORKS AT HIM FROM 10... | Home | Eyeball | Contusions, Abrasions | Treated/Untreated and Released | . Counting Drug and Alchol Use . The number of people injuried with positive results for drug or alcohol use was very insignificant compared to overall count of injuries. . # Count Drug and Alcohol for df_injury df_da = df_injury.groupby([&#39;Drug&#39;,&#39;Alcohol&#39;])[&#39;Age&#39;].count().reset_index(name=&#39;count&#39;) df_da . . Drug Alcohol count . 0 No | No | 1487 | . 1 No | Yes | 40 | . 2 Yes | No | 1 | . 3 Yes | Yes | 4 | . Drug and Alcohol Usuage (Bar Plot) . #define figure size sns.set(rc={&quot;figure.figsize&quot;:(15, 6)}) #set background to white sns.set_style(&quot;white&quot;) fig, ax = plt.subplots(1,2) sns.countplot(df_injury[&#39;Drug&#39;], ax=ax[0], palette=&quot;Oranges_r&quot;) ax[0].set_title(&#39;Drug Related Incidents&#39;, fontdict = {&#39;fontsize&#39;: 15}) ax[0].set(ylabel=&#39;Counts&#39;, xlabel=&#39;&#39;) sns.countplot(df_injury[&#39;Alcohol&#39;], ax=ax[1], palette=&quot;Blues_r&quot;) ax[1].set_title(&#39;Alcohol Related Incidents&#39;, fontdict = {&#39;fontsize&#39;: 15}) ax[1].set(ylabel=&#39;&#39;, xlabel=&#39;&#39;) # remove spines sns.despine(left=True) #save to png # fig.savefig(&quot;Drug/Alcohol Counts.png&quot;) plt.show() fig.savefig(&#39;Drug_and_Alcohol_Counts.png&#39;) plt.show() . . # Sort DF by treatment date df_injury.sort_values(by = &#39;Treatment_Date&#39;, inplace = True) . . Incident Counts by Year (Bar Plot) . # Incident Counts by Year BarGraph #define figure size sns.set(rc = {&quot;figure.figsize&quot;:(12,8)}) #set background to white sns.set_style(&quot;white&quot;) treamentDates = df_injury[&#39;Treatment_Date&#39;].dt.year.value_counts().sort_index().reset_index() ax = sns.barplot(y=&quot;Treatment_Date&quot;, x=&quot;index&quot;, data=treamentDates, palette=&quot;Blues&quot;) #set x,y labels ax.set(xlabel=&#39;&#39;, ylabel=&#39;Incident Counts&#39;) #set titles ax.set_title(&#39;Firework Injury Counts by Year&#39;, fontdict = {&#39;fontsize&#39;: 15}) #remove spiens sns.despine(left=True) #save to png ax.figure.savefig(&quot;Firework Injury Counts by Year.png&quot;) plt.show() . . Incident Counts by Gender (Bar Plot) . # Incident Counts by Sex incidentSex = df_injury[&#39;Sex&#39;].value_counts().reset_index(name=&#39;incidents&#39;) #define figure size sns.set(rc={&quot;figure.figsize&quot;:(12, 8)}) #set background to white sns.set_style(&quot;white&quot;) ax = sns.barplot(x=&quot;incidents&quot;, y=&quot;index&quot;, data=incidentSex, palette=&quot;Blues_r&quot;) #set x,y labels ax.set(xlabel=&#39;&#39;, ylabel=&#39;Injury Counts&#39;) #set titles ax.set_title(&#39;Firework Injury Counts by Gender (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:15}) #remove spines sns.despine(left=True) #save to png ax.figure.savefig(&quot;Firework Injury Counts by Gender.png&quot;) plt.show() . . Incident Counts by Body Part (Bar Plot) . # Incident Counts by Body Part #define figure size sns.set(rc={&quot;figure.figsize&quot;:(12,8)}) #set background color sns.set_style(&quot;white&quot;) incidentBp = df_injury[&#39;Body_Part&#39;].value_counts().reset_index(name=&#39;incidents&#39;).head(23) ax = sns.barplot(x=&quot;incidents&quot;, y=&quot;index&quot;, data=incidentBp, palette=&quot;Blues_r&quot;) #set x,y labels ax.set(xlabel=&#39;&#39;, ylabel=&#39;&#39;) #set title ax.set_title(&#39;Firework Injury Counts by Body Part (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:15}) #remove spines sns.despine(left=True) #save to png ax.figure.savefig(&quot;Incident Counts by Body Part.png&quot;) plt.show() . . Fixing Age Column | . Details The Age column list not only numeric ages but also includes category codes for individuals under the age of 2 year old. Individuals that are under 2 years old are given a code starting with 200 combined with their age in months. If the patient is older than 115 years old, code the age as 115 and indicate the actual age in the Comment. If the ED record indicates the patient was born on January 1, 1900, please verify the patient’s age with hospital staff – some hospitals use this date when the patient’s age is unknown. Note CPSC prefers that coders use the Date of Birth variable in lieu of the age variable. Mistakes in coded ages are common when patients have birthdays after the date of treatment and before the NEISS coder codes the case. Hospital medical record systems automatically update the age of the patient daily. # Age Codes age_code = {0:&#39;No Recorded Age&#39;, 2:&#39;2 Years Old&#39;, 45:&#39;45 Years Old&#39;, 100:&#39;100 Years Old&#39;, 102:&#39;102 Years Old&#39;, 201:&#39;Three Weeks Old&#39;, 201:&#39;Four Weeks Old&#39;, 201:&#39;Seven Weeks Old&#39;, 202:&#39;Ten Weeks Old&#39;, 209:&#39;Nine Months Old&#39;, 212:&#39;Twelve months (one year)&#39;, 218:&#39;Eighteen months&#39;} # my_dict = {&#39;Computer&#39;:1500,&#39;Monitor&#39;:300,&#39;Printer&#39;:150,&#39;Desk&#39;:250} age_codes = pd.DataFrame(list(age_code.items()),columns = [&#39;Age_Code&#39;,&#39;Description&#39;]) #Display Age Codes and Description age_codes . . Age_Code Description . 0 0 | No Recorded Age | . 1 2 | 2 Years Old | . 2 45 | 45 Years Old | . 3 100 | 100 Years Old | . 4 102 | 102 Years Old | . 5 201 | Seven Weeks Old | . 6 202 | Ten Weeks Old | . 7 209 | Nine Months Old | . 8 212 | Twelve months (one year) | . 9 218 | Eighteen months | . # create fix_age col # &#39;fix_age&#39; col represents ages only in numeric years, def fix_age(age): if 201 &lt;= age &lt;=209: age = 0 return age elif age &gt;=201: age = 1 return age else: return age df_injury[&#39;Age_Fix&#39;] = df_injury[&#39;Age&#39;].apply(fix_age) df_injury.query(&#39;Age&gt;=200&#39;).head() df_injury.to_csv(&#39;df_injury_clean2.csv&#39;) . . Age Groups (Histogram) . Details The histogram below shows that the majority of firework related injuries that were reported occured with indivuals under the age of 40. The largest grouping belonged to individuals under the age of 20, which is also below the legal drinking age in the US. # Histogram of Ages #set figsize sns.set(rc={&quot;figure.figsize&quot;:(8, 8)}) #set background color sns.set_style(&quot;white&quot;) ax = sns.histplot(data=df_injury, x=&#39;Age_Fix&#39;, bins=5) #set x,y labels ax.set(xlabel=&#39;Age&#39;, ylabel=&#39;Counts&#39;) #set title ax.set_title(&#39;Firework Injury Counts by Age (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:15}) #remove spines sns.despine(left=True) #save to png ax.figure.savefig(&quot;Incident Counts by Age_Hist.png&quot;) plt.show() . . Incident Counts by Age (Bar Plot) . # Incident Counts by Age (Age_Fix) #define figure size sns.set(rc={&quot;figure.figsize&quot;:(30, 12)}) #set background color sns.set_style(&quot;white&quot;) incidentAge = df_injury[&#39;Age_Fix&#39;].value_counts().reset_index(name=&#39;incidents&#39;) ax = sns.barplot(y=&quot;incidents&quot;, x=&quot;index&quot;, data=incidentAge, palette=&quot;Blues_r&quot;) #set x,y labels ax.set(xlabel=&#39;Age&#39;, ylabel=&#39;Count&#39;) #set title ax.set_title(&#39;Firework Injury Counts by Age (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:30}) #remove spines sns.despine(left=True) #save to png ax.figure.savefig(&quot;Incident Counts by Age_Bar.png&quot;) plt.show() . . Age, Year, Gender (Swarm Plot) . # Swarm graph by age, year, and gender #define figure size sns.set(rc={&quot;figure.figsize&quot;:(14,10)}) #set background color sns.set_style(&quot;white&quot;) ax = sns.swarmplot(data = df_injury, x = df_injury[&#39;Treatment_Date&#39;].dt.year, y = &quot;Age_Fix&quot;, hue = &quot;Sex&quot;, palette = &quot;Blues_r&quot;) #set x,y labels ax.set(xlabel = &#39;Year&#39;, ylabel = &#39;Age&#39;) #set title ax.set_title(&#39;Firework Injury Counts by Age&#39;, fontdict = {&#39;fontsize&#39;:18}) #remove spines sns.despine(left=True) #save to png ax.figure.savefig(&quot;Incident Counts by Age_Swarm.png&quot;) plt.show() . . Incident Counts by Disposition (Bar Plot) . # Incident Counts by Disposition incidentDis = df_injury[&#39;Disposition&#39;].value_counts().reset_index(name=&#39;incidents&#39;).head() #define figure size sns.set(rc={&quot;figure.figsize&quot;:(10,10)}) #set background color sns.set_style(&quot;white&quot;) ax = sns.barplot(x = &quot;incidents&quot;, y = &quot;index&quot;, data = incidentDis, palette = &quot;Blues_r&quot;) #set x,y labels ax.set(xlabel = &#39;&#39;, ylabel = &#39;&#39;) ax.set_title(&#39;Firework Injury Counts by Disposition (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:18}) #set title # ax.set_ylabel(&#39;&#39;, fontdict= {&#39;fontsize&#39;:25}) #remove spine sns.despine(left=True) #save to png # ax.figure.savefig(&quot;Incident Counts by Disposition.png&quot;) plt.show() . . Incident Counts by Diagnosis (Bar Plot) . # Incident Counts by Diagnosis incidentDia = df_injury[&#39;Diagnosis&#39;].value_counts().reset_index(name=&#39;incidents&#39;).head(10) #define figure size sns.set(rc={&quot;figure.figsize&quot;:(14,10)}) #set background color sns.set_style(&quot;white&quot;) ax = sns.barplot(x = &quot;incidents&quot;, y = &quot;index&quot;, data = incidentDia, palette = &quot;Blues_r&quot;) #set x,y labels ax.set(xlabel = &#39;&#39;, ylabel = &#39;&#39;) #set title ax.set_title(&#39;Firework Injury Counts by Diagnosis (2016-2020)&#39;, fontdict = {&#39;fontsize&#39;:18}) #remove spine sns.despine(left=True) # #set y axis labels (shortened longer labels to fit for print out) # ax.set_yticklabels([&#39;Burns&#39;, &#39;Contusions&#39;, &#39;Abrasions&#39;,&#39;Other/Not Stated&#39;, # &#39;Laceration&#39;,&#39;Fracture&#39;,&#39;Amputation&#39;,&#39;Foreign body&#39;, # &#39;Internal organ&#39;,&#39;Strain or Sprain&#39;,&#39;Avulsion&#39;, # &#39;Anoxia&#39;,&#39;Puncture&#39;,&#39;Poisoning&#39;,&#39;Dermatitis&#39;, &#39;Conjunctivitis&#39;, # &#39;Concussions&#39;,&#39;Hematoma&#39;]) #save to png ax.figure.savefig(&quot;Incident Counts by Diagnosis.png&quot;) plt.show() . . Import Firework Sales Data (State) . sales_state = &#39;https://github.com/drusho/fireworks_data_exploration/raw/main/data/data_raw/State%20Imports%20by%20HS%20Commodities.csv&#39; df_sales_st = pd.read_csv(sales_state,skiprows=4,usecols=[0,1,2,3]) df_sales_st.head() . . State Commodity Time Total Value ($US) . 0 Alabama | 360410 Fireworks | 2016 | 29,602,090 | . 1 Alabama | 360410 Fireworks | 2017 | 19,396,430 | . 2 Alabama | 360410 Fireworks | 2018 | 26,399,895 | . 3 Alabama | 360410 Fireworks | 2019 | 28,353,392 | . 4 Alabama | 360410 Fireworks | 2020 | 23,141,950 | . Web Scraping for State Abbreviations . Details The dataframe was missing state abbreviations that are needed to plot data onto a map using Plotly. Used pandas function &#39;read_hml&#39; to read tables from a website that contact state and state abbreviation data. #WebScrap State Abbreviations #scrap state names and abbrev states_abrev = pd.read_html(&#39;https://abbreviations.yourdictionary.com/articles/state-abbrev.html&#39;)[0].iloc[1:,:2] #scrap US territory names and abbrev territories = pd.read_html(&#39;https://abbreviations.yourdictionary.com/articles/state-abbrev.html&#39;)[1].iloc[[2,5],:2] #merge dfs st_at = states_abrev.merge(territories,how=&#39;outer&#39;).sort_values(by=0).reset_index(drop=True) #rename cols st_at.rename(columns={0:&#39;State&#39;,1:&#39;Abbrevation&#39;},inplace=True) st_at.head() . . State Abbrevation . 0 Alabama | AL | . 1 Alaska | AK | . 2 Arizona | AZ | . 3 Arkansas | AR | . 4 California | CA | . Merging State Abbreviations with Master Dataframe . #merge abbrevation with state sales data df_sales_st2 = df_sales_st.merge(st_at,how=&#39;inner&#39;) df_sales_st2.head() . . State Commodity Time Total Value ($US) Abbrevation . 0 Alabama | 360410 Fireworks | 2016 | 29,602,090 | AL | . 1 Alabama | 360410 Fireworks | 2017 | 19,396,430 | AL | . 2 Alabama | 360410 Fireworks | 2018 | 26,399,895 | AL | . 3 Alabama | 360410 Fireworks | 2019 | 28,353,392 | AL | . 4 Alabama | 360410 Fireworks | 2020 | 23,141,950 | AL | . Changing Data Types for Time and Sales . #Convert Sales to int dtype df_sales_st2[&#39;Total Value ($US)&#39;] = df_sales_st2[&#39;Total Value ($US)&#39;].str.replace(&#39;,&#39;,&#39;&#39;).astype(&#39;int&#39;) df_sales_st2.head(2) #Convert Time to datetime dtype df_sales_st2[&#39;Time&#39;] = df_sales_st2[&#39;Time&#39;].str.replace(&#39;2021 through April&#39;,&#39;2021&#39;) df_sales_st2[&#39;Time&#39;] = pd.to_datetime(df_sales_st2[&#39;Time&#39;]) #export csv of clean data df_sales_st2.to_csv(&#39;df_state_sales_clean.csv&#39;) . . df_sales_st2.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 285 entries, 0 to 284 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 State 285 non-null object 1 Commodity 285 non-null object 2 Time 285 non-null datetime64[ns] 3 Total Value ($US) 285 non-null int64 4 Abbrevation 285 non-null object dtypes: datetime64[ns](1), int64(1), object(3) memory usage: 13.4+ KB . . Top 20 Sales per State (Bar Plot) . # Visualization State Sales (Bar Plot) st_sales = df_sales_st2.copy() st_sales = st_sales.groupby(&#39;State&#39;)[&#39;Total Value ($US)&#39;].sum().reset_index(name=&#39;Sales&#39;).sort_values(by=&#39;Sales&#39;,ascending=False).reset_index(drop=True).head(20) st_sales.sort_values(by=&#39;Sales&#39;,ascending=True,inplace=True) fig = px.bar(st_sales, y=&#39;State&#39;, x=&#39;Sales&#39;, orientation=&#39;h&#39;, color_continuous_scale=&#39;Blues&#39;, color=&quot;Sales&quot;) fig.update_layout({&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255, 0.9)&quot;}, title={&#39;text&#39;: &quot;Firework Total Sales ($USD) 2016-2020&quot;, &#39;y&#39;:.98, &#39;x&#39;:.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}) fig.show() # # save fig to image # fig.write_image(&quot;Total Firework Sales ($USD) 2016-2020.png&quot;, width=1980, height=1080) # fig.write_html(&quot;Total Firework Sales ($USD) 2016-2020.html&quot;) . . . . State Sales (Scatter Plot) . Note Plotly currently does not have the ability to position colorscales to horizontal. # Visualization State Sales (Scatter Plot) df_sales_st2.sort_values(by=&#39;State&#39;,ascending=False,inplace=True) fig = px.scatter(df_sales_st2, y=&quot;State&quot;, x=&quot;Time&quot;, color=&quot;Total Value ($US)&quot;, size=&#39;Total Value ($US)&#39;, width=800, height=1100, color_continuous_scale=&#39;Blues&#39;) #change background and legend background to white fig.update_layout({&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255, 0.9)&quot;}, # &quot;paper_bgcolor&quot;: &quot;rgba(255,255,255, 0.9)&quot;}, title={&#39;text&#39;: &quot;Firework Sales ($USD)&quot;, &#39;y&#39;:.98, &#39;x&#39;:.5,&#39;xanchor&#39;:&#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis=dict(title=&#39;&#39;), yaxis=dict(title=&#39;&#39;)) fig.show() # save fig to image fig.write_image(&quot;Firework Sales ($USD) (scatter_plot).png&quot;, width=800, height=1000) fig.write_html(&quot;Firework Sales ($USD) (scatter_plot).html&quot;) . . . . State Sales (Heatmap Plot of US) . fig = px.choropleth(df_sales_st2, # Input Pandas DataFrame locations=&quot;Abbrevation&quot;, # DataFrame column with locations color=&quot;Total Value ($US)&quot;, # DataFrame column with color values hover_name=&quot;Abbrevation&quot;, # DataFrame column hover info locationmode = &#39;USA-states&#39;, # Set to plot as US States color_continuous_scale=&#39;Blues&#39;) fig.update_layout( title={ &#39;text&#39;: &quot;Firework Total Sales ($USD) 2016-2020&quot;, &#39;y&#39;:.95, &#39;x&#39;:.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, geo_scope=&#39;usa&#39;) # Plot only the USA instead of globe fig.show() # save fig to image fig.write_image(&quot;Total State Firework Sales ($USD) 2016-2020 (map).png&quot;, width=1980, height=1080) fig.write_html(&quot;Total State Firework Sales ($USD) 2016-2020 (map).html&quot;) . . . . Putting It All Together . Combining injury and sales data. | Sales and Injury Correlation | . Total Sales Groupby Year . # Total Sales groupby Year sales_year = df_sales_st2.groupby(df_sales_st2[&#39;Time&#39;].dt.year).sum().reset_index(drop=False) sales_year.rename(columns={&#39;Time&#39;:&#39;Year&#39;,&#39;Total Value ($US)&#39;:&#39;Sales&#39;},inplace=True) sales_year . . Year Sales . 0 2016 | 307825710 | . 1 2017 | 279962808 | . 2 2018 | 331072715 | . 3 2019 | 320021354 | . 4 2020 | 300987616 | . 5 2021 | 157186415 | . Total Injuries Groupby Year . # df_injury.groupby([&#39;Treatment_Date&#39;] df_injury_count = df_injury.groupby(df_injury[&#39;Treatment_Date&#39;].dt.year)[&#39;Age&#39;].count().reset_index(name=&#39;Count&#39;) df_injury_count.rename(columns={&#39;Treatment_Date&#39;:&#39;Year&#39;},inplace=True) df_injury_count . . Year Count . 0 2016 | 268 | . 1 2017 | 329 | . 2 2018 | 234 | . 3 2019 | 261 | . 4 2020 | 440 | . Merging Sales and Injury DataFrame on Year . # Merge sales and injury dfs on year df_merged = sales_year.merge(df_injury_count,how=&#39;left&#39;) df_merged . . Year Sales Count . 0 2016 | 307825710 | 268.0 | . 1 2017 | 279962808 | 329.0 | . 2 2018 | 331072715 | 234.0 | . 3 2019 | 320021354 | 261.0 | . 4 2020 | 300987616 | 440.0 | . 5 2021 | 157186415 | NaN | . Determining Correlation of New DataFrame . # Correlation df_merged.corr() . . Year Sales Count . Year 1.000000 | -0.585906 | 0.529818 | . Sales -0.585906 | 1.000000 | -0.590087 | . Count 0.529818 | -0.590087 | 1.000000 | . Results . Injuries Ages 0-20 showed the highest rate of injury. Injury rates by age decrease with age. The 60+ age groups showed the lowest rate of injury Injuries to the hands, face, and eyes were the most common, while injuries to lower extemities were less common. Sales The state of Missouri held the record for most spent on fireworks (over 250 million dollars over the past 5 years). For comparision, Alaska spent around 560,000 dollars with the last five years Correlation There was no significate correlation between the number of injuries in a year compared to the number of sales. Tools Used . Tools Matplotlib, Pandas, Plotly, Seaborn, Resources . Firework Injury Reports . | USA Trade Census . | Source Details Source 1 consisted multiple excel incident reports involving fireworks over the past 5 years taken from the U.S. Consumer Product Safety Commission (CPSC). The NEISS injury data are gathered from the emergency departments (ED) of 96 hospitals selected as a probability sample of all U.S. hospitals with 24-hour EDs and at least 6 inpatient beds. Each participating NEISS hospital is hand-selected by CPSC because it provides an important representation of all other hospitals of its size and unique characteristics in the U.S. Source 2 conatins Sales and Trade data for each state regarding fireworks. Reports data range from 2016 to April 2021.",
            "url": "https://drusho.github.io/pandas/plotly/seaborn/2021/07/04/_07_03_Analysis_of_US_Firework_Sales_and_Injuries.html",
            "relUrl": "/pandas/plotly/seaborn/2021/07/04/_07_03_Analysis_of_US_Firework_Sales_and_Injuries.html",
            "date": " • Jul 4, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "I have a passion for using data to tell stories and discover meaningful insights. I have been a hobbiest programmer most of life and discovered Data Science and Analytics on accident while looking for methods to automate work projects such as creating advanced spreadsheet formulas for cleaning and merging. At one point I even installed a SuperSQL in Google Sheets as a means to create a locaized database because discovering python and other modern data handling methods. . I’m currently based out of Orlando, FL where I am currenlty enrolled in an MS Data Analytics (Big Data) program at the University of Central Florida. When I’m not programming or reading about Data Science you can usually find my playing with photography, practicing yoga, or learning to cook some korean/indian food. .",
          "url": "https://drusho.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Dashboards",
          "content": "Tableau . COVID-19 (12/2019 - 06/2020) .",
          "url": "https://drusho.github.io/dashboards/",
          "relUrl": "/dashboards/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Home",
          "content": "",
          "url": "https://drusho.github.io/",
          "relUrl": "/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://drusho.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}